"""
Audio Input & Preparation Page
Upload / record audio, overview, visualization, basic preprocessing
"""
import streamlit as st
import os
import sys
import tempfile

# ================== PATH SETUP ==================
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from app.components.layout import apply_custom_css, render_page_header
from app.components.audio_visualizer import render_audio_visualization
from app.components.footer import render_footer
from core.audio.audio_processor import (
    load_audio,
    get_audio_info,
    preprocess_audio,
)
from core.audio.ffmpeg_setup import ensure_ffmpeg

# ================== ENV SETUP ==================
ensure_ffmpeg(silent=True)
apply_custom_css()

st.set_page_config(
    page_title="Audio Input - Vietnamese Speech to Text",
    page_icon="üé§",
    layout="wide",
)

# ================== SESSION STATE ==================
def init_state():
    defaults = {
        "audio_data": None,
        "audio_sr": None,
        "audio_info": None,
        "audio_ready": False,
        "audio_source": None,
        "preprocess_mode": "recommended",  # simple, recommended, advanced
        "preprocess_normalize": True,
        "preprocess_trim_silence": False,
        "preprocess_remove_noise": False,
        "preprocess_target_sr": 16000,
        "preprocess_noise_cutoff": 80,
    }
    for k, v in defaults.items():
        st.session_state.setdefault(k, v)

init_state()

# ================== HEADER ==================
render_page_header("Audio Input & Preparation", "Upload ho·∫∑c ghi √¢m audio, ki·ªÉm tra v√† chu·∫©n b·ªã cho ASR pipeline", "üé§")

# ================== INPUT ==================
tab_upload, tab_record = st.tabs(["üì§ Upload", "üéôÔ∏è Record"])

with tab_upload:
    uploaded_file = st.file_uploader(
        "Audio file (wav, mp3, flac, m4a, ogg)",
        type=["wav", "mp3", "flac", "m4a", "ogg"],
    )

    if uploaded_file:
        with st.spinner("Loading audio..."):
            audio_data, sr = load_audio(uploaded_file)

        if audio_data is None:
            st.error("‚ùå Kh√¥ng th·ªÉ load audio")
        else:
            st.session_state.audio_data = audio_data
            st.session_state.audio_sr = sr
            st.session_state.audio_info = get_audio_info(audio_data, sr)
            st.session_state.audio_ready = False
            st.session_state.audio_source = uploaded_file
            st.success("‚úÖ Audio loaded")

with tab_record:
    st.info("Ghi √¢m tr·ª±c ti·∫øp t·ª´ tr√¨nh duy·ªát (t√πy ch·ªçn)")

    try:
        from audio_recorder_streamlit import audio_recorder

        audio_bytes = audio_recorder()

        if audio_bytes:
            st.audio(audio_bytes, format="audio/wav")

            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                tmp.write(audio_bytes)
                tmp_path = tmp.name

            try:
                audio_data, sr = load_audio(tmp_path)
                if audio_data is not None:
                    st.session_state.audio_data = audio_data
                    st.session_state.audio_sr = sr
                    st.session_state.audio_info = get_audio_info(audio_data, sr)
                    st.session_state.audio_ready = False
                    st.session_state.audio_source = audio_bytes
                    st.success("‚úÖ Audio recorded")
            finally:
                try:
                    os.unlink(tmp_path)
                except Exception:
                    pass
    except ImportError:
        st.warning("C√†i ƒë·∫∑t audio-recorder-streamlit ƒë·ªÉ d√πng ch·ª©c nƒÉng ghi √¢m")

# ================== OVERVIEW ==================
if st.session_state.audio_data is not None:
    st.divider()
    st.subheader("üìÑ Audio Overview")

    info = st.session_state.audio_info
    c1, c2, c3 = st.columns(3)
    c1.metric("Duration", f"{info['duration']:.1f}s")
    c2.metric("Sample Rate", f"{st.session_state.audio_sr} Hz")
    c3.metric("Samples", f"{len(st.session_state.audio_data):,}")

    if isinstance(st.session_state.audio_source, bytes):
        st.audio(st.session_state.audio_source, format="audio/wav")
    else:
        st.audio(st.session_state.audio_source)

    # ================== VISUALIZATION ==================
    with st.expander("üìä Waveform & Visualization"):
        render_audio_visualization(
            st.session_state.audio_data,
            st.session_state.audio_sr,
        )

    # ================== PREPROCESSING ==================
    st.divider()
    st.subheader("üîß Ti·ªÅn X·ª≠ L√Ω √Çm Thanh")
    
    st.markdown("""
    <div style='background-color: #f0f2f6; padding: 15px; border-radius: 5px; margin-bottom: 20px;'>
        <strong>üí° H∆∞·ªõng d·∫´n:</strong> Ch·ªçn ch·∫ø ƒë·ªô ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa b·∫°n. 
        <strong>ƒê·ªÅ xu·∫•t</strong> l√† l·ª±a ch·ªçn t·ªët nh·∫•t cho h·∫ßu h·∫øt tr∆∞·ªùng h·ª£p.
    </div>
    """, unsafe_allow_html=True)
    
    # Preset Mode Selection
    mode_options = {
        "simple": {
            "name": "üéØ ƒê∆°n gi·∫£n",
            "description": "T·ª± ƒë·ªông x·ª≠ l√Ω v·ªõi c√†i ƒë·∫∑t m·∫∑c ƒë·ªãnh - Ph√π h·ª£p cho ng∆∞·ªùi d√πng kh√¥ng chuy√™n",
            "icon": "üéØ"
        },
        "recommended": {
            "name": "‚≠ê ƒê·ªÅ xu·∫•t (Khuy·∫øn ngh·ªã)",
            "description": "C√†i ƒë·∫∑t t·ªëi ∆∞u cho ch·∫•t l∆∞·ª£ng v√† t·ªëc ƒë·ªô - Ph√π h·ª£p cho h·∫ßu h·∫øt ng∆∞·ªùi d√πng",
            "icon": "‚≠ê"
        },
        "advanced": {
            "name": "‚öôÔ∏è N√¢ng cao",
            "description": "T√πy ch·ªânh chi ti·∫øt c√°c th√¥ng s·ªë - D√†nh cho ng∆∞·ªùi d√πng c√≥ kinh nghi·ªám",
            "icon": "‚öôÔ∏è"
        }
    }
    
    # Display preset selection with better UI
    preset_cols = st.columns(3)
    selected_mode = st.session_state.preprocess_mode
    
    with preset_cols[0]:
        if st.button(
            mode_options["simple"]["name"],
            use_container_width=True,
            type="primary" if selected_mode == "simple" else "secondary",
            key="preset_simple"
        ):
            selected_mode = "simple"
            st.session_state.preprocess_mode = "simple"
            st.session_state.preprocess_normalize = True
            st.session_state.preprocess_trim_silence = False
            st.session_state.preprocess_remove_noise = False
            st.session_state.preprocess_target_sr = 16000
            st.rerun()
    
    with preset_cols[1]:
        if st.button(
            mode_options["recommended"]["name"],
            use_container_width=True,
            type="primary" if selected_mode == "recommended" else "secondary",
            key="preset_recommended"
        ):
            selected_mode = "recommended"
            st.session_state.preprocess_mode = "recommended"
            st.session_state.preprocess_normalize = True
            st.session_state.preprocess_trim_silence = False
            st.session_state.preprocess_remove_noise = False
            st.session_state.preprocess_target_sr = 16000
            st.rerun()
    
    with preset_cols[2]:
        if st.button(
            mode_options["advanced"]["name"],
            use_container_width=True,
            type="primary" if selected_mode == "advanced" else "secondary",
            key="preset_advanced"
        ):
            selected_mode = "advanced"
            st.session_state.preprocess_mode = "advanced"
            st.rerun()
    
    # Show description of selected preset
    current_preset = mode_options[st.session_state.preprocess_mode]
    st.info(f"**{current_preset['name']}**: {current_preset['description']}")
    
    # Configuration based on preset mode
    st.markdown("### ‚öôÔ∏è C√†i ƒê·∫∑t")
    
    if st.session_state.preprocess_mode == "simple":
        # Simple mode: Show minimal, user-friendly options
        st.markdown("""
        **Ch·∫ø ƒë·ªô ƒê∆°n gi·∫£n** s·∫Ω t·ª± ƒë·ªông:
        - ‚úÖ Chu·∫©n h√≥a √¢m l∆∞·ª£ng (normalize) ƒë·ªÉ √¢m thanh r√µ r√†ng h∆°n
        - ‚úÖ Gi·ªØ nguy√™n sample rate 16kHz (t·ªëi ∆∞u cho nh·∫≠n di·ªán gi·ªçng n√≥i)
        - ‚ùå Kh√¥ng c·∫Øt im l·∫∑ng (gi·ªØ nguy√™n th·ªùi l∆∞·ª£ng)
        - ‚ùå Kh√¥ng l·ªçc nhi·ªÖu (gi·ªØ nguy√™n ch·∫•t l∆∞·ª£ng g·ªëc)
        """)
        
        # Just show what will be applied
        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown("**Chu·∫©n h√≥a √¢m l∆∞·ª£ng:** ‚úÖ B·∫≠t")
        with col2:
            st.markdown("**Sample Rate:** 16kHz")
        with col3:
            st.markdown("**C·∫Øt im l·∫∑ng:** ‚ùå T·∫Øt")
        
        # Use saved values
        normalize = st.session_state.preprocess_normalize
        trim_silence = st.session_state.preprocess_trim_silence
        remove_noise = st.session_state.preprocess_remove_noise
        target_sr = st.session_state.preprocess_target_sr
        
    elif st.session_state.preprocess_mode == "recommended":
        # Recommended mode: Show recommended settings with explanations
        st.markdown("""
        **Ch·∫ø ƒë·ªô ƒê·ªÅ xu·∫•t** s·ª≠ d·ª•ng c√°c c√†i ƒë·∫∑t ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u:
        """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            normalize = st.checkbox(
                "‚úÖ Chu·∫©n h√≥a √¢m l∆∞·ª£ng",
                value=st.session_state.preprocess_normalize,
                help="ƒêi·ªÅu ch·ªânh √¢m l∆∞·ª£ng v·ªÅ m·ª©c chu·∫©n ƒë·ªÉ c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng nh·∫≠n di·ªán. N√™n b·∫≠t trong h·∫ßu h·∫øt tr∆∞·ªùng h·ª£p."
            )
            st.session_state.preprocess_normalize = normalize
            
            trim_silence = st.checkbox(
                "‚úÇÔ∏è C·∫Øt im l·∫∑ng ·ªü ƒë·∫ßu/cu·ªëi",
                value=st.session_state.preprocess_trim_silence,
                help="T·ª± ƒë·ªông lo·∫°i b·ªè kho·∫£ng im l·∫∑ng ·ªü ƒë·∫ßu v√† cu·ªëi file. T·∫Øt n·∫øu b·∫°n mu·ªën gi·ªØ nguy√™n th·ªùi l∆∞·ª£ng g·ªëc."
            )
            st.session_state.preprocess_trim_silence = trim_silence
        
        with col2:
            target_sr = st.selectbox(
                "üéµ T·∫ßn s·ªë l·∫•y m·∫´u (Sample Rate)",
                [16000, 22050, 44100],
                index=[16000, 22050, 44100].index(st.session_state.preprocess_target_sr),
                help="16kHz l√† t·ªëi ∆∞u cho nh·∫≠n di·ªán gi·ªçng n√≥i. Ch·ªâ ƒë·ªïi n·∫øu c√≥ y√™u c·∫ßu ƒë·∫∑c bi·ªát."
            )
            st.session_state.preprocess_target_sr = target_sr
            
            remove_noise = st.checkbox(
                "üîá Gi·∫£m nhi·ªÖu t·∫ßn s·ªë th·∫•p",
                value=st.session_state.preprocess_remove_noise,
                help="L·ªçc b·ªè ti·∫øng ·ªìn t·∫ßn s·ªë th·∫•p (nh∆∞ ti·∫øng gi√≥, rung ƒë·ªông). Ch·ªâ b·∫≠t khi audio c√≥ nhi·ªÅu nhi·ªÖu."
            )
            st.session_state.preprocess_remove_noise = remove_noise
    
    else:  # advanced mode
        # Advanced mode: Show all options with technical details
        st.markdown("""
        **Ch·∫ø ƒë·ªô N√¢ng cao** cho ph√©p t√πy ch·ªânh chi ti·∫øt t·∫•t c·∫£ c√°c th√¥ng s·ªë k·ªπ thu·∫≠t.
        """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            normalize = st.checkbox(
                "Chu·∫©n h√≥a √¢m l∆∞·ª£ng (Normalize Amplitude)",
                value=st.session_state.preprocess_normalize,
                help="Peak normalization: y = y / max(|y|). ƒê∆∞a t√≠n hi·ªáu v·ªÅ bi√™n ƒë·ªô t·ªëi ƒëa ¬±1.0"
            )
            st.session_state.preprocess_normalize = normalize
            
            trim_silence = st.checkbox(
                "C·∫Øt im l·∫∑ng (Trim Silence)",
                value=st.session_state.preprocess_trim_silence,
                help="S·ª≠ d·ª•ng librosa.effects.trim() ƒë·ªÉ lo·∫°i b·ªè silence ·ªü ƒë·∫ßu v√† cu·ªëi audio d·ª±a tr√™n energy threshold"
            )
            st.session_state.preprocess_trim_silence = trim_silence
        
        with col2:
            target_sr = st.selectbox(
                "Target Sample Rate (Hz)",
                [8000, 16000, 22050, 44100],
                index=[8000, 16000, 22050, 44100].index(st.session_state.preprocess_target_sr) if st.session_state.preprocess_target_sr in [8000, 16000, 22050, 44100] else 1,
                help="T·∫ßn s·ªë l·∫•y m·∫´u m·ª•c ti√™u. 16kHz l√† chu·∫©n cho ASR. Resample s·ª≠ d·ª•ng librosa.resample()"
            )
            st.session_state.preprocess_target_sr = target_sr
            
            remove_noise = st.checkbox(
                "L·ªçc nhi·ªÖu t·∫ßn s·ªë th·∫•p (High-pass Filter)",
                value=st.session_state.preprocess_remove_noise,
                help="√Åp d·ª•ng Butterworth high-pass filter ƒë·ªÉ lo·∫°i b·ªè noise d∆∞·ªõi cutoff frequency"
            )
            st.session_state.preprocess_remove_noise = remove_noise
        
        # Advanced noise reduction settings
        if remove_noise:
            with st.expander("üîß C√†i ƒë·∫∑t chi ti·∫øt - L·ªçc nhi·ªÖu"):
                noise_cutoff = st.slider(
                    "T·∫ßn s·ªë c·∫Øt (Cutoff Frequency) - Hz",
                    min_value=40,
                    max_value=200,
                    value=st.session_state.preprocess_noise_cutoff,
                    step=10,
                    help="T·∫ßn s·ªë d∆∞·ªõi m·ª©c n√†y s·∫Ω b·ªã l·ªçc b·ªè. 80Hz l√† gi√° tr·ªã m·∫∑c ƒë·ªãnh h·ª£p l√Ω cho h·∫ßu h·∫øt tr∆∞·ªùng h·ª£p."
                )
                st.session_state.preprocess_noise_cutoff = noise_cutoff
                st.caption("‚ö†Ô∏è L∆∞u √Ω: L·ªçc qu√° m·∫°nh c√≥ th·ªÉ l√†m gi·∫£m ch·∫•t l∆∞·ª£ng gi·ªçng n√≥i. Ch·ªâ ƒëi·ªÅu ch·ªânh khi c·∫ßn thi·∫øt.")
    
    # Apply preprocessing button
    st.divider()
    col_btn1, col_btn2, col_btn3 = st.columns([1, 2, 1])
    
    with col_btn2:
        if st.button("üöÄ √Åp D·ª•ng Ti·ªÅn X·ª≠ L√Ω", type="primary", use_container_width=True):
            with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω √¢m thanh..."):
                try:
                    audio = st.session_state.audio_data.copy()
                    original_sr = st.session_state.audio_sr  # Store original sample rate
                    was_resampled = False
                    
                    # Apply preprocessing
                    # For advanced mode with noise reduction, we'll handle it separately with custom cutoff
                    use_standard_noise_reduction = remove_noise and st.session_state.preprocess_mode != "advanced"
                    
                    audio = preprocess_audio(
                        audio,
                        original_sr,
                        normalize=normalize,
                        remove_noise=use_standard_noise_reduction,
                    )
                    
                    # Advanced mode: apply noise reduction with custom cutoff
                    if st.session_state.preprocess_mode == "advanced" and remove_noise:
                        from scipy import signal
                        cutoff = st.session_state.preprocess_noise_cutoff
                        sos = signal.butter(10, cutoff, 'hp', fs=original_sr, output='sos')
                        audio = signal.sosfilt(sos, audio)
                    
                    # Resample if needed
                    if target_sr != original_sr:
                        import librosa
                        audio = librosa.resample(audio, orig_sr=original_sr, target_sr=target_sr)
                        st.session_state.audio_sr = target_sr
                        was_resampled = True
                    
                    # Trim silence if enabled
                    if trim_silence:
                        import librosa
                        audio, _ = librosa.effects.trim(audio)
                    
                    st.session_state.audio_data = audio
                    st.session_state.audio_info = get_audio_info(audio, st.session_state.audio_sr)
                    st.session_state.audio_ready = True
                    
                    st.success("‚úÖ Ti·ªÅn x·ª≠ l√Ω ho√†n t·∫•t! Audio ƒë√£ s·∫µn s√†ng cho b∆∞·ªõc nh·∫≠n di·ªán gi·ªçng n√≥i.")
                    
                    # Show what was applied
                    applied_settings = []
                    if normalize:
                        applied_settings.append("‚úÖ Chu·∫©n h√≥a √¢m l∆∞·ª£ng")
                    if trim_silence:
                        applied_settings.append("‚úÖ C·∫Øt im l·∫∑ng")
                    if remove_noise:
                        cutoff_value = st.session_state.preprocess_noise_cutoff if st.session_state.preprocess_mode == 'advanced' else 80
                        applied_settings.append(f"‚úÖ L·ªçc nhi·ªÖu ({cutoff_value}Hz)")
                    if was_resampled:
                        applied_settings.append(f"‚úÖ Resample {original_sr}Hz ‚Üí {target_sr}Hz")
                    
                    if applied_settings:
                        st.info("**ƒê√£ √°p d·ª•ng:** " + " | ".join(applied_settings))
                    
                except Exception as e:
                    st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω audio: {str(e)}")
                    st.exception(e)

    # ================== NEXT STEP ==================
    st.divider()
    st.info("üéØ Audio ƒë√£ s·∫µn s√†ng cho b∆∞·ªõc Transcription & Speaker Diarization")

    if st.button("‚û°Ô∏è Go to Transcription", type="primary", use_container_width=True):
        st.switch_page("pages/2_üìù_Transcription.py")

else:
    st.info("üëÜ Upload ho·∫∑c ghi √¢m audio ƒë·ªÉ b·∫Øt ƒë·∫ßu")

# ===== Footer =====
render_footer()
