"""
Audio Input & Preparation Page
Upload / record audio, overview, visualization, basic preprocessing
"""
import streamlit as st
import os
import sys
import tempfile

# ================== PATH SETUP ==================
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from app.components.layout import apply_custom_css, render_page_header
from app.components.audio_visualizer import render_audio_visualization
from app.components.footer import render_footer
from core.audio.audio_processor import (
    load_audio,
    get_audio_info,
    preprocess_audio,
)
from core.audio.ffmpeg_setup import ensure_ffmpeg

# ================== ENV SETUP ==================
ensure_ffmpeg(silent=True)
apply_custom_css()

st.set_page_config(
    page_title="Audio Input - Vietnamese Speech to Text",
    page_icon="üé§",
    layout="wide",
)

# ================== SESSION STATE ==================
def init_state():
    defaults = {
        "audio_data": None,
        "audio_sr": None,
        "audio_info": None,
        "audio_ready": False,
        "audio_source": None,
        "preprocess_mode": "recommended",  # simple, recommended, advanced
        "preprocess_normalize": True,
        "preprocess_trim_silence": False,
        "preprocess_remove_noise": False,
        "preprocess_target_sr": 16000,
        "preprocess_noise_cutoff": 80,
    }
    for k, v in defaults.items():
        st.session_state.setdefault(k, v)

init_state()

# ================== HEADER ==================
render_page_header("Audio Input & Preparation", "Upload ho·∫∑c ghi √¢m audio, ki·ªÉm tra v√† chu·∫©n b·ªã cho ASR pipeline", "üé§")

# ================== INPUT ==================
tab_upload, tab_record = st.tabs(["üì§ Upload", "üéôÔ∏è Record"])

with tab_upload:
    uploaded_file = st.file_uploader(
        "Audio file (wav, mp3, flac, m4a, ogg)",
        type=["wav", "mp3", "flac", "m4a", "ogg"],
        help="T·∫£i l√™n file audio ƒë·ªÉ b·∫Øt ƒë·∫ßu. H·ªó tr·ª£ c√°c ƒë·ªãnh d·∫°ng: WAV, MP3, FLAC, M4A, OGG"
    )

    if uploaded_file:
        # Validation: Check file size (max 200MB)
        max_size_mb = 200
        file_size_mb = uploaded_file.size / (1024 * 1024)
        
        if file_size_mb > max_size_mb:
            st.error(f"‚ùå File qu√° l·ªõn ({file_size_mb:.1f}MB). K√≠ch th∆∞·ªõc t·ªëi ƒëa: {max_size_mb}MB")
            st.info("üí° **G·ª£i √Ω**: H√£y n√©n file ho·∫∑c chia nh·ªè file audio")
        else:
            with st.spinner("‚è≥ ƒêang t·∫£i audio..."):
                try:
                    audio_data, sr = load_audio(uploaded_file)
                    
                    if audio_data is None:
                        st.error("‚ùå Kh√¥ng th·ªÉ load audio. Vui l√≤ng ki·ªÉm tra file c√≥ h·ª£p l·ªá kh√¥ng.")
                        st.info("üí° **G·ª£i √Ω**: \n- ƒê·∫£m b·∫£o file kh√¥ng b·ªã h·ªèng\n- Th·ª≠ chuy·ªÉn ƒë·ªïi sang ƒë·ªãnh d·∫°ng WAV\n- Ki·ªÉm tra file c√≥ ph·∫£i l√† audio kh√¥ng")
                    else:
                        # Additional validation: Check duration
                        duration = len(audio_data) / sr
                        if duration < 0.1:
                            st.warning("‚ö†Ô∏è File audio qu√° ng·∫Øn (< 0.1 gi√¢y). C√≥ th·ªÉ kh√¥ng ph·∫£i file audio h·ª£p l·ªá.")
                        elif duration > 3600:  # 1 hour
                            st.warning(f"‚ö†Ô∏è File audio r·∫•t d√†i ({duration/60:.1f} ph√∫t). Qu√° tr√¨nh x·ª≠ l√Ω c√≥ th·ªÉ m·∫•t nhi·ªÅu th·ªùi gian.")
                        
                        st.session_state.audio_data = audio_data
                        st.session_state.audio_sr = sr
                        st.session_state.audio_info = get_audio_info(audio_data, sr)
                        st.session_state.audio_ready = False
                        st.session_state.audio_source = uploaded_file
                        st.success(f"‚úÖ ƒê√£ t·∫£i audio th√†nh c√¥ng! ({file_size_mb:.1f}MB, {duration:.1f}s)")
                        
                except Exception as e:
                    st.error(f"‚ùå L·ªói khi t·∫£i audio: {str(e)}")
                    st.info("üí° **G·ª£i √Ω**: \n- Ki·ªÉm tra file c√≥ b·ªã h·ªèng kh√¥ng\n- Th·ª≠ file audio kh√°c\n- ƒê·∫£m b·∫£o ƒë·ªãnh d·∫°ng ƒë∆∞·ª£c h·ªó tr·ª£")

with tab_record:
    st.info("üéôÔ∏è Ghi √¢m tr·ª±c ti·∫øp t·ª´ tr√¨nh duy·ªát. Nh·∫•n n√∫t ƒë·ªÉ b·∫Øt ƒë·∫ßu/d·ª´ng ghi √¢m.")
    
    # Initialize recorded audio in session state
    if "recorded_audio_bytes" not in st.session_state:
        st.session_state.recorded_audio_bytes = None
    if "recorded_audio_hash" not in st.session_state:
        st.session_state.recorded_audio_hash = None
    
    try:
        from audio_recorder_streamlit import audio_recorder
        import hashlib

        # Show recorder
        audio_bytes = audio_recorder(
            text="",
            recording_color="#e74c3c",
            neutral_color="#6c757d",
            icon_name="microphone",
            icon_size="2x",
        )

        # Check if new audio was recorded (different from stored)
        if audio_bytes is not None:
            # Create hash to check if audio is new
            audio_hash = hashlib.md5(audio_bytes).hexdigest()
            
            # Check if this is new audio (different hash from what we have)
            if st.session_state.recorded_audio_hash != audio_hash:
                st.session_state.recorded_audio_bytes = audio_bytes
                st.session_state.recorded_audio_hash = audio_hash
                
                # Process the new audio
                with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω audio ƒë√£ ghi..."):
                    try:
                        # Create temp file for audio bytes
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                            tmp.write(audio_bytes)
                            tmp_path = tmp.name
                        
                        try:
                            # Load audio using load_audio function
                            audio_data, sr = load_audio(tmp_path)
                            
                            if audio_data is not None and len(audio_data) > 0:
                                # Calculate duration
                                duration = len(audio_data) / sr
                                
                                # Validate duration
                                if duration < 0.1:
                                    st.warning("‚ö†Ô∏è Audio qu√° ng·∫Øn (< 0.1 gi√¢y). Vui l√≤ng ghi √¢m l·∫°i.")
                                else:
                                    # Save to session state
                                    st.session_state.audio_data = audio_data
                                    st.session_state.audio_sr = sr
                                    st.session_state.audio_info = get_audio_info(audio_data, sr)
                                    st.session_state.audio_ready = False
                                    st.session_state.audio_source = audio_bytes
                                    
                                    st.success(f"‚úÖ ƒê√£ ghi √¢m th√†nh c√¥ng! ({duration:.1f}s)")
                                    
                                    # Show audio player
                                    st.audio(audio_bytes, format="audio/wav")
                            else:
                                st.error("‚ùå Kh√¥ng th·ªÉ load audio ƒë√£ ghi. Vui l√≤ng th·ª≠ l·∫°i.")
                        finally:
                            # Clean up temp file
                            try:
                                if os.path.exists(tmp_path):
                                    os.unlink(tmp_path)
                            except Exception:
                                pass
                    except Exception as e:
                        st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω audio ƒë√£ ghi: {str(e)}")
                        st.info("üí° **G·ª£i √Ω**: \n- ƒê·∫£m b·∫£o microphone ho·∫°t ƒë·ªông\n- Ki·ªÉm tra quy·ªÅn truy c·∫≠p microphone\n- Th·ª≠ ghi √¢m l·∫°i")
                        with st.expander("üîç Chi ti·∫øt l·ªói"):
                            st.exception(e)
        
        # Show previously recorded audio if available
        elif st.session_state.recorded_audio_bytes is not None:
            st.info("üìº Audio ƒë√£ ghi tr∆∞·ªõc ƒë√≥:")
            st.audio(st.session_state.recorded_audio_bytes, format="audio/wav")
            
            # Option to clear recorded audio
            if st.button("üóëÔ∏è X√≥a audio ƒë√£ ghi", key="clear_recorded_audio"):
                st.session_state.recorded_audio_bytes = None
                st.session_state.audio_data = None
                st.session_state.audio_sr = None
                st.session_state.audio_info = None
                st.session_state.audio_source = None
                st.success("‚úÖ ƒê√£ x√≥a audio ƒë√£ ghi")
                st.rerun()
        
        # Show current audio status if loaded
        if st.session_state.audio_data is not None and st.session_state.recorded_audio_bytes is not None:
            duration = st.session_state.audio_info.get('duration', 0) if st.session_state.audio_info else 0
            st.info(f"‚úÖ Audio ƒë√£ s·∫µn s√†ng ({duration:.1f}s). B·∫°n c√≥ th·ªÉ ti·∫øp t·ª•c v·ªõi ti·ªÅn x·ª≠ l√Ω ho·∫∑c transcription.")
            
    except ImportError:
        st.warning("‚ö†Ô∏è Ch∆∞a c√†i ƒë·∫∑t `audio-recorder-streamlit`. C√†i ƒë·∫∑t b·∫±ng l·ªánh: `pip install audio-recorder-streamlit`")
        st.info("üí° Sau khi c√†i ƒë·∫∑t, l√†m m·ªõi trang ƒë·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng ghi √¢m.")
    except Exception as e:
        st.error(f"‚ùå L·ªói khi kh·ªüi t·∫°o audio recorder: {str(e)}")
        st.info("üí° **G·ª£i √Ω**: \n- Ki·ªÉm tra quy·ªÅn truy c·∫≠p microphone\n- ƒê·∫£m b·∫£o tr√¨nh duy·ªát h·ªó tr·ª£ Web Audio API\n- Th·ª≠ tr√™n tr√¨nh duy·ªát kh√°c (Chrome, Edge)")

# ================== OVERVIEW ==================
if st.session_state.audio_data is not None:
    st.divider()
    st.subheader("üìÑ Audio Overview")

    info = st.session_state.audio_info
    c1, c2, c3 = st.columns(3)
    c1.metric("Duration", f"{info['duration']:.1f}s")
    c2.metric("Sample Rate", f"{st.session_state.audio_sr} Hz")
    c3.metric("Samples", f"{len(st.session_state.audio_data):,}")

    if isinstance(st.session_state.audio_source, bytes):
        st.audio(st.session_state.audio_source, format="audio/wav")
    else:
        st.audio(st.session_state.audio_source)

    # ================== VISUALIZATION ==================
    with st.expander("üìä Waveform & Visualization"):
        render_audio_visualization(
            st.session_state.audio_data,
            st.session_state.audio_sr,
        )

    # ================== PREPROCESSING ==================
    st.divider()
    st.subheader("üîß Ti·ªÅn X·ª≠ L√Ω √Çm Thanh")
    
    # Default to recommended mode
    if st.session_state.preprocess_mode not in ["simple", "recommended", "advanced"]:
        st.session_state.preprocess_mode = "recommended"
    
    # Simplified mode selection - default to recommended, hide advanced by default
    use_advanced = st.checkbox(
        "‚öôÔ∏è Hi·ªÉn th·ªã t√πy ch·ªçn n√¢ng cao",
        value=False,
        help="B·∫≠t ƒë·ªÉ xem v√† t√πy ch·ªânh c√°c th√¥ng s·ªë k·ªπ thu·∫≠t chi ti·∫øt"
    )
    
    if use_advanced:
        # Show mode selection only if advanced is enabled
        mode_options = {
            "simple": "üéØ ƒê∆°n gi·∫£n - T·ª± ƒë·ªông x·ª≠ l√Ω v·ªõi c√†i ƒë·∫∑t m·∫∑c ƒë·ªãnh",
            "recommended": "‚≠ê ƒê·ªÅ xu·∫•t - C√†i ƒë·∫∑t t·ªëi ∆∞u (Khuy·∫øn ngh·ªã)",
            "advanced": "‚öôÔ∏è N√¢ng cao - T√πy ch·ªânh chi ti·∫øt"
        }
        
        selected_mode = st.radio(
            "Ch·ªçn ch·∫ø ƒë·ªô x·ª≠ l√Ω:",
            options=list(mode_options.keys()),
            format_func=lambda x: mode_options[x],
            index=list(mode_options.keys()).index(st.session_state.preprocess_mode),
            help="Ch·∫ø ƒë·ªô 'ƒê·ªÅ xu·∫•t' l√† l·ª±a ch·ªçn t·ªët nh·∫•t cho h·∫ßu h·∫øt tr∆∞·ªùng h·ª£p"
        )
        st.session_state.preprocess_mode = selected_mode
    else:
        # Default to recommended mode
        st.session_state.preprocess_mode = "recommended"
        st.info("üí° **Ch·∫ø ƒë·ªô ƒê·ªÅ xu·∫•t**: S·ª≠ d·ª•ng c√†i ƒë·∫∑t t·ªëi ∆∞u cho ch·∫•t l∆∞·ª£ng v√† t·ªëc ƒë·ªô. B·∫≠t 'T√πy ch·ªçn n√¢ng cao' ƒë·ªÉ t√πy ch·ªânh.")
    
    # Configuration based on preset mode
    st.markdown("### ‚öôÔ∏è C√†i ƒê·∫∑t")
    
    if st.session_state.preprocess_mode == "simple":
        # Simple mode: Show minimal, user-friendly options
        st.markdown("""
        **Ch·∫ø ƒë·ªô ƒê∆°n gi·∫£n** s·∫Ω t·ª± ƒë·ªông:
        - ‚úÖ Chu·∫©n h√≥a √¢m l∆∞·ª£ng ƒë·ªÉ √¢m thanh r√µ r√†ng h∆°n
        - ‚úÖ Gi·ªØ nguy√™n sample rate 16kHz (t·ªëi ∆∞u cho nh·∫≠n di·ªán gi·ªçng n√≥i)
        - ‚ùå Kh√¥ng c·∫Øt im l·∫∑ng (gi·ªØ nguy√™n th·ªùi l∆∞·ª£ng)
        - ‚ùå Kh√¥ng l·ªçc nhi·ªÖu (gi·ªØ nguy√™n ch·∫•t l∆∞·ª£ng g·ªëc)
        """)
        
        # Use saved values
        normalize = True
        trim_silence = False
        remove_noise = False
        target_sr = 16000
        
    elif st.session_state.preprocess_mode == "recommended":
        # Recommended mode: Show recommended settings with explanations
        st.markdown("""
        **Ch·∫ø ƒë·ªô ƒê·ªÅ xu·∫•t** s·ª≠ d·ª•ng c√°c c√†i ƒë·∫∑t ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u:
        """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            normalize = st.checkbox(
                "‚úÖ Chu·∫©n h√≥a √¢m l∆∞·ª£ng",
                value=st.session_state.preprocess_normalize,
                help="ƒêi·ªÅu ch·ªânh √¢m l∆∞·ª£ng v·ªÅ m·ª©c chu·∫©n ƒë·ªÉ c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng nh·∫≠n di·ªán. N√™n b·∫≠t trong h·∫ßu h·∫øt tr∆∞·ªùng h·ª£p."
            )
            st.session_state.preprocess_normalize = normalize
            
            trim_silence = st.checkbox(
                "‚úÇÔ∏è C·∫Øt im l·∫∑ng ·ªü ƒë·∫ßu/cu·ªëi",
                value=st.session_state.preprocess_trim_silence,
                help="T·ª± ƒë·ªông lo·∫°i b·ªè kho·∫£ng im l·∫∑ng ·ªü ƒë·∫ßu v√† cu·ªëi file. T·∫Øt n·∫øu b·∫°n mu·ªën gi·ªØ nguy√™n th·ªùi l∆∞·ª£ng g·ªëc."
            )
            st.session_state.preprocess_trim_silence = trim_silence
        
        with col2:
            target_sr = st.selectbox(
                "üéµ T·∫ßn s·ªë l·∫•y m·∫´u (Sample Rate)",
                [16000, 22050, 44100],
                index=[16000, 22050, 44100].index(st.session_state.preprocess_target_sr),
                help="16kHz l√† t·ªëi ∆∞u cho nh·∫≠n di·ªán gi·ªçng n√≥i. Ch·ªâ ƒë·ªïi n·∫øu c√≥ y√™u c·∫ßu ƒë·∫∑c bi·ªát."
            )
            st.session_state.preprocess_target_sr = target_sr
            
            remove_noise = st.checkbox(
                "üîá Gi·∫£m nhi·ªÖu t·∫ßn s·ªë th·∫•p",
                value=st.session_state.preprocess_remove_noise,
                help="L·ªçc b·ªè ti·∫øng ·ªìn t·∫ßn s·ªë th·∫•p (nh∆∞ ti·∫øng gi√≥, rung ƒë·ªông). Ch·ªâ b·∫≠t khi audio c√≥ nhi·ªÅu nhi·ªÖu."
            )
            st.session_state.preprocess_remove_noise = remove_noise
    
    else:  # advanced mode
        # Advanced mode: Show all options with technical details
        st.markdown("""
        **Ch·∫ø ƒë·ªô N√¢ng cao** cho ph√©p t√πy ch·ªânh chi ti·∫øt t·∫•t c·∫£ c√°c th√¥ng s·ªë k·ªπ thu·∫≠t.
        """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            normalize = st.checkbox(
                "Chu·∫©n h√≥a √¢m l∆∞·ª£ng (Normalize Amplitude)",
                value=st.session_state.preprocess_normalize,
                help="Peak normalization: y = y / max(|y|). ƒê∆∞a t√≠n hi·ªáu v·ªÅ bi√™n ƒë·ªô t·ªëi ƒëa ¬±1.0"
            )
            st.session_state.preprocess_normalize = normalize
            
            trim_silence = st.checkbox(
                "C·∫Øt im l·∫∑ng (Trim Silence)",
                value=st.session_state.preprocess_trim_silence,
                help="S·ª≠ d·ª•ng librosa.effects.trim() ƒë·ªÉ lo·∫°i b·ªè silence ·ªü ƒë·∫ßu v√† cu·ªëi audio d·ª±a tr√™n energy threshold"
            )
            st.session_state.preprocess_trim_silence = trim_silence
        
        with col2:
            target_sr = st.selectbox(
                "Target Sample Rate (Hz)",
                [8000, 16000, 22050, 44100],
                index=[8000, 16000, 22050, 44100].index(st.session_state.preprocess_target_sr) if st.session_state.preprocess_target_sr in [8000, 16000, 22050, 44100] else 1,
                help="T·∫ßn s·ªë l·∫•y m·∫´u m·ª•c ti√™u. 16kHz l√† chu·∫©n cho ASR. Resample s·ª≠ d·ª•ng librosa.resample()"
            )
            st.session_state.preprocess_target_sr = target_sr
            
            remove_noise = st.checkbox(
                "L·ªçc nhi·ªÖu t·∫ßn s·ªë th·∫•p (High-pass Filter)",
                value=st.session_state.preprocess_remove_noise,
                help="√Åp d·ª•ng Butterworth high-pass filter ƒë·ªÉ lo·∫°i b·ªè noise d∆∞·ªõi cutoff frequency"
            )
            st.session_state.preprocess_remove_noise = remove_noise
        
        # Advanced noise reduction settings
        if remove_noise:
            with st.expander("üîß C√†i ƒë·∫∑t chi ti·∫øt - L·ªçc nhi·ªÖu"):
                noise_cutoff = st.slider(
                    "T·∫ßn s·ªë c·∫Øt (Cutoff Frequency) - Hz",
                    min_value=40,
                    max_value=200,
                    value=st.session_state.preprocess_noise_cutoff,
                    step=10,
                    help="T·∫ßn s·ªë d∆∞·ªõi m·ª©c n√†y s·∫Ω b·ªã l·ªçc b·ªè. 80Hz l√† gi√° tr·ªã m·∫∑c ƒë·ªãnh h·ª£p l√Ω cho h·∫ßu h·∫øt tr∆∞·ªùng h·ª£p."
                )
                st.session_state.preprocess_noise_cutoff = noise_cutoff
                st.caption("‚ö†Ô∏è L∆∞u √Ω: L·ªçc qu√° m·∫°nh c√≥ th·ªÉ l√†m gi·∫£m ch·∫•t l∆∞·ª£ng gi·ªçng n√≥i. Ch·ªâ ƒëi·ªÅu ch·ªânh khi c·∫ßn thi·∫øt.")
    
    # Preview before processing
    st.markdown("---")
    st.markdown("### üëÅÔ∏è Xem tr∆∞·ªõc")
    
    preview_col1, preview_col2 = st.columns(2)
    with preview_col1:
        st.markdown("**Tr∆∞·ªõc khi x·ª≠ l√Ω:**")
        if isinstance(st.session_state.audio_source, bytes):
            st.audio(st.session_state.audio_source, format="audio/wav")
        else:
            st.audio(st.session_state.audio_source)
    
    with preview_col2:
        st.markdown("**Sau khi x·ª≠ l√Ω:**")
        st.info("Audio ƒë√£ x·ª≠ l√Ω s·∫Ω hi·ªÉn th·ªã ·ªü ƒë√¢y sau khi b·∫°n nh·∫•n '√Åp d·ª•ng'")
    
    # Apply preprocessing button
    st.divider()
    col_btn1, col_btn2, col_btn3 = st.columns([1, 2, 1])
    
    with col_btn2:
        if st.button("üöÄ √Åp D·ª•ng Ti·ªÅn X·ª≠ L√Ω", type="primary", use_container_width=True):
            with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω √¢m thanh..."):
                try:
                    audio = st.session_state.audio_data.copy()
                    original_sr = st.session_state.audio_sr  # Store original sample rate
                    was_resampled = False
                    
                    # Apply preprocessing
                    # For advanced mode with noise reduction, we'll handle it separately with custom cutoff
                    use_standard_noise_reduction = remove_noise and st.session_state.preprocess_mode != "advanced"
                    
                    audio = preprocess_audio(
                        audio,
                        original_sr,
                        normalize=normalize,
                        remove_noise=use_standard_noise_reduction,
                    )
                    
                    # Advanced mode: apply noise reduction with custom cutoff
                    if st.session_state.preprocess_mode == "advanced" and remove_noise:
                        from scipy import signal
                        cutoff = st.session_state.preprocess_noise_cutoff
                        sos = signal.butter(10, cutoff, 'hp', fs=original_sr, output='sos')
                        audio = signal.sosfilt(sos, audio)
                    
                    # Resample if needed
                    if target_sr != original_sr:
                        import librosa
                        audio = librosa.resample(audio, orig_sr=original_sr, target_sr=target_sr)
                        st.session_state.audio_sr = target_sr
                        was_resampled = True
                    
                    # Trim silence if enabled
                    if trim_silence:
                        import librosa
                        audio, _ = librosa.effects.trim(audio)
                    
                    st.session_state.audio_data = audio
                    st.session_state.audio_info = get_audio_info(audio, st.session_state.audio_sr)
                    st.session_state.audio_ready = True
                    
                    st.success("‚úÖ Ti·ªÅn x·ª≠ l√Ω ho√†n t·∫•t! Audio ƒë√£ s·∫µn s√†ng cho b∆∞·ªõc nh·∫≠n di·ªán gi·ªçng n√≥i.")
                    
                    # Show what was applied
                    applied_settings = []
                    if normalize:
                        applied_settings.append("‚úÖ Chu·∫©n h√≥a √¢m l∆∞·ª£ng")
                    if trim_silence:
                        applied_settings.append("‚úÖ C·∫Øt im l·∫∑ng")
                    if remove_noise:
                        cutoff_value = st.session_state.preprocess_noise_cutoff if st.session_state.preprocess_mode == 'advanced' else 80
                        applied_settings.append(f"‚úÖ L·ªçc nhi·ªÖu ({cutoff_value}Hz)")
                    if was_resampled:
                        applied_settings.append(f"‚úÖ Resample {original_sr}Hz ‚Üí {target_sr}Hz")
                    
                    if applied_settings:
                        st.info("**ƒê√£ √°p d·ª•ng:** " + " | ".join(applied_settings))
                    
                    # Show preview of processed audio
                    st.audio(audio, sample_rate=st.session_state.audio_sr)
                    
                except Exception as e:
                    error_msg = str(e)
                    st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω audio: {error_msg}")
                    
                    # Provide helpful suggestions
                    if "memory" in error_msg.lower() or "out of memory" in error_msg.lower():
                        st.info("üí° **G·ª£i √Ω**: File audio qu√° l·ªõn. H√£y th·ª≠:\n- Chia nh·ªè file audio\n- S·ª≠ d·ª•ng ch·∫ø ƒë·ªô 'ƒê∆°n gi·∫£n'\n- Gi·∫£m sample rate")
                    elif "format" in error_msg.lower() or "codec" in error_msg.lower():
                        st.info("üí° **G·ª£i √Ω**: ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. H√£y th·ª≠:\n- Chuy·ªÉn ƒë·ªïi sang WAV ho·∫∑c MP3\n- Ki·ªÉm tra file c√≥ b·ªã h·ªèng kh√¥ng")
                    else:
                        with st.expander("üîç Chi ti·∫øt l·ªói"):
                            st.exception(e)

    # ================== NEXT STEP ==================
    st.divider()
    st.info("üéØ Audio ƒë√£ s·∫µn s√†ng cho b∆∞·ªõc Transcription & Speaker Diarization")

    if st.button("‚û°Ô∏è Go to Transcription", type="primary", use_container_width=True):
        st.switch_page("pages/2_üìù_Transcription.py")

else:
    st.info("üëÜ Upload ho·∫∑c ghi √¢m audio ƒë·ªÉ b·∫Øt ƒë·∫ßu")

# ===== Footer =====
render_footer()
