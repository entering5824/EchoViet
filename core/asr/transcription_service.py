"""
Module transcription sá»­ dá»¥ng Whisper
"""
import os
import sys
import whisper
import torch
import streamlit as st
from typing import Optional, Dict, List
import numpy as np
import time
from core.audio.audio_processor import _make_safe_temp_copy

def check_python_version():
    """
    Kiá»ƒm tra Python version vÃ  cáº£nh bÃ¡o náº¿u khÃ´ng phÃ¹ há»£p vá»›i Streamlit Cloud
    
    Returns:
        Tuple (is_valid: bool, warning_message: Optional[str])
    """
    version = sys.version_info
    if version.major == 3 and 9 <= version.minor <= 10:
        return True, None
    
    warning_msg = (
        f"âš ï¸ Python {version.major}.{version.minor} Ä‘Æ°á»£c phÃ¡t hiá»‡n. "
        f"Streamlit Cloud khuyáº¿n nghá»‹ Python 3.9-3.10. "
        f"Python 3.11+ hoáº·c 3.8- cÃ³ thá»ƒ gÃ¢y lá»—i vá»›i Whisper."
    )
    return False, warning_msg

# Check Python version early
_python_version_valid, _python_version_warning = check_python_version()
if _python_version_warning:
    try:
        import streamlit as st
        st.warning(_python_version_warning)
    except:
        print(_python_version_warning)

@st.cache_resource
def load_whisper_model(model_size="base"):
    """Load Whisper model vá»›i cache"""
    try:
        # On Streamlit Cloud, force CPU even if CUDA is detected
        if os.getenv("STREAMLIT_SHARING", "").lower() == "true" or os.getenv("STREAMLIT_SERVER_BASE_URL", ""):
            device = "cpu"  # Force CPU on Cloud
        else:
            device = "cuda" if torch.cuda.is_available() else "cpu"
        
        model = whisper.load_model(model_size, device=device)
        return model, device
    except KeyError as ke:
        # Handle "missing field" errors
        error_msg = f"Missing field error: {str(ke)}"
        st.error(f"âŒ Lá»—i 'missing field' khi load Whisper model. ÄÃ¢y thÆ°á»ng do cache model bá»‹ lá»—i.")
        st.warning("""
        **Kháº¯c phá»¥c:**
        1. XÃ³a cache Whisper: `rm -rf ~/.cache/whisper` (Linux) hoáº·c xÃ³a thÆ° má»¥c cache trÃªn Windows
        2. Restart á»©ng dá»¥ng vÃ  thá»­ láº¡i
        """)
        return None, None
    except RuntimeError as re:
        # Handle CUDA unavailable errors
        error_msg = str(re)
        if "cuda" in error_msg.lower() or "CUDA" in error_msg:
            st.error(f"âŒ Lá»—i CUDA: {error_msg}")
            st.info("ğŸ’¡ Äang tá»± Ä‘á»™ng chuyá»ƒn sang CPU mode...")
            # Retry with CPU
            try:
                model = whisper.load_model(model_size, device="cpu")
                return model, "cpu"
            except Exception as cpu_err:
                st.error(f"âŒ KhÃ´ng thá»ƒ load model ngay cáº£ vá»›i CPU: {str(cpu_err)}")
                return None, None
        else:
            raise  # Re-raise if not CUDA-related
    except Exception as e:
        error_msg = str(e)
        # Kiá»ƒm tra lá»—i network
        if "getaddrinfo failed" in error_msg or "urlopen error" in error_msg.lower():
            st.error(f"âŒ Lá»—i káº¿t ná»‘i máº¡ng khi táº£i Whisper model. Vui lÃ²ng kiá»ƒm tra káº¿t ná»‘i internet hoáº·c thá»­ láº¡i sau.")
            st.info("ğŸ’¡ Whisper cáº§n táº£i model tá»« internet láº§n Ä‘áº§u tiÃªn. Model sáº½ Ä‘Æ°á»£c cache sau khi táº£i thÃ nh cÃ´ng.")
        else:
            st.error(f"Lá»—i khi load Whisper model: {error_msg}")
        return None, None

def get_vietnamese_initial_prompt(include_english: bool = True) -> str:
    """
    Táº¡o initial prompt tá»‘i Æ°u cho tiáº¿ng Viá»‡t vÃ  mixed language
    
    Args:
        include_english: CÃ³ bao gá»“m tá»« tiáº¿ng Anh phá»• biáº¿n khÃ´ng
    
    Returns:
        Initial prompt string
    """
    # CÃ¡c tá»« khÃ³a tiáº¿ng Viá»‡t phá»• biáº¿n Ä‘á»ƒ giÃºp model nháº­n diá»‡n tá»‘t hÆ¡n
    vietnamese_common_words = [
        "xin chÃ o", "cáº£m Æ¡n", "vÃ¢ng", "khÃ´ng", "Ä‘Æ°á»£c", "khÃ´ng Ä‘Æ°á»£c",
        "hÃ´m nay", "ngÃ y mai", "hÃ´m qua", "bÃ¢y giá»", "sau Ä‘Ã³",
        "cÃ´ng ty", "dá»± Ã¡n", "cuá»™c há»p", "khÃ¡ch hÃ ng", "Ä‘á»‘i tÃ¡c",
        "viá»‡c lÃ m", "nhiá»‡m vá»¥", "má»¥c tiÃªu", "káº¿t quáº£", "giáº£i phÃ¡p",
        "tá»‘t", "tuyá»‡t vá»i", "xuáº¥t sáº¯c", "cháº¥p nháº­n Ä‘Æ°á»£c", "cáº§n cáº£i thiá»‡n",
        "Ä‘Ãºng", "sai", "chÃ­nh xÃ¡c", "rÃµ rÃ ng", "hiá»ƒu",
        "váº¥n Ä‘á»", "thÃ¡ch thá»©c", "cÆ¡ há»™i", "rá»§i ro", "nguy cÆ¡"
    ]
    
    english_common_words = [
        "okay", "yes", "no", "thank you", "hello", "meeting",
        "project", "customer", "partner", "solution", "problem"
    ]
    
    # Táº¡o prompt vá»›i context vá» mixed language
    if include_english:
        prompt = "ÄÃ¢y lÃ  Ä‘oáº¡n ghi Ã¢m tiáº¿ng Viá»‡t, cÃ³ thá»ƒ cÃ³ má»™t sá»‘ tá»« tiáº¿ng Anh nhÆ°: " + ", ".join(english_common_words[:5])
        prompt += ". CÃ¡c tá»« tiáº¿ng Viá»‡t phá»• biáº¿n: " + ", ".join(vietnamese_common_words[:10])
    else:
        prompt = "ÄÃ¢y lÃ  Ä‘oáº¡n ghi Ã¢m tiáº¿ng Viá»‡t. " + ", ".join(vietnamese_common_words[:15])
    
    return prompt


def transcribe_audio(model, audio_path_or_array, sr=16000, language="vi", 
                     task="transcribe", verbose=False,
                     initial_prompt: Optional[str] = None,
                     beam_size: int = 5,
                     temperature: float = 0.0,
                     condition_on_previous_text: bool = True,
                     best_of: int = 5,
                     use_vietnamese_optimization: bool = True):
    """
    Transcribe audio vá»›i Whisper - CHUáº¨N cho tiáº¿ng Viá»‡t
    
    QUAN TRá»ŒNG: LuÃ´n dÃ¹ng language="vi", fp16=False, verbose=False
    Ä‘á»ƒ trÃ¡nh "1 táº£ng chá»¯" vÃ  Ä‘áº£m báº£o cháº¥t lÆ°á»£ng tá»‘t nháº¥t.
    """
    """
    Transcribe audio sá»­ dá»¥ng Whisper vá»›i tá»‘i Æ°u cho tiáº¿ng Viá»‡t
    
    Args:
        model: Whisper model
        audio_path_or_array: ÄÆ°á»ng dáº«n file hoáº·c numpy array
        sr: Sample rate
        language: NgÃ´n ngá»¯ (vi cho tiáº¿ng Viá»‡t)
        task: "transcribe" hoáº·c "translate"
        verbose: Hiá»ƒn thá»‹ thÃ´ng tin chi tiáº¿t
        initial_prompt: Initial prompt Ä‘á»ƒ guide model (tá»± Ä‘á»™ng táº¡o náº¿u None vÃ  use_vietnamese_optimization=True)
        beam_size: Beam size cho beam search (5 = tá»‘t cho tiáº¿ng Viá»‡t)
        temperature: Temperature (0.0 = greedy, >0 = sampling)
        condition_on_previous_text: Sá»­ dá»¥ng context tá»« segment trÆ°á»›c
        best_of: Sá»‘ lÆ°á»£ng candidates Ä‘á»ƒ chá»n best
        use_vietnamese_optimization: Tá»± Ä‘á»™ng Ã¡p dá»¥ng tá»‘i Æ°u cho tiáº¿ng Viá»‡t
    """
    try:
        if model is None:
            return None
        
        # If audio_path_or_array is a filepath, preflight-check and create safe copy if needed
        audio_path_to_use = audio_path_or_array
        if isinstance(audio_path_or_array, str):
            # Normalize path for Windows (resolve any path issues with absolute paths)
            audio_path_to_use = os.path.normpath(os.path.abspath(audio_path_or_array))
            
            # CRITICAL: Verify file exists before transcribe (prevents WinError 2)
            if not os.path.exists(audio_path_to_use):
                error_msg = f"File khÃ´ng tá»“n táº¡i: {audio_path_to_use}"
                st.error(f"âŒ {error_msg}")
                st.warning("ğŸ’¡ File cÃ³ thá»ƒ Ä‘Ã£ bá»‹ xÃ³a hoáº·c path khÃ´ng Ä‘Ãºng. Vui lÃ²ng kiá»ƒm tra láº¡i.")
                return None
            
            if not os.path.isfile(audio_path_to_use):
                error_msg = f"Path khÃ´ng pháº£i lÃ  file: {audio_path_to_use}"
                st.error(f"âŒ {error_msg}")
                return None
            
            # Retry a few times for transient file access issues (Windows file lock)
            file_accessible = False
            for attempt in range(3):
                try:
                    # Test if file is readable
                    with open(audio_path_to_use, 'rb') as test_file:
                        test_file.read(1)  # Read 1 byte to test
                    file_accessible = True
                    break
                except PermissionError:
                    st.warning(f"âš ï¸ File Ä‘ang Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi process khÃ¡c. Retry {attempt + 1}/3...")
                    time.sleep(0.2 * (attempt + 1))
                    continue
                except Exception as file_err:
                    # Try to create a safe temp copy if original filename could be problematic
                    try:
                        tmp_copy = _make_safe_temp_copy(audio_path_to_use)
                        audio_path_to_use = tmp_copy
                        file_accessible = True
                        break
                    except Exception:
                        time.sleep(0.1 * (attempt + 1))
                        continue
            
            if not file_accessible:
                st.error(f"âŒ KhÃ´ng thá»ƒ truy cáº­p file: {audio_path_to_use}")
                st.warning("ğŸ’¡ File cÃ³ thá»ƒ Ä‘ang bá»‹ khÃ³a bá»Ÿi process khÃ¡c hoáº·c khÃ´ng cÃ³ quyá»n truy cáº­p.")
                return None

        # Final check before transcribe
        if isinstance(audio_path_to_use, str):
            if not os.path.exists(audio_path_to_use):
                st.error(f"âŒ File khÃ´ng tá»“n táº¡i trÆ°á»›c khi transcribe: {audio_path_to_use}")
                return None

        # Táº¡o initial prompt náº¿u cáº§n
        effective_prompt = initial_prompt
        if use_vietnamese_optimization and language == "vi" and initial_prompt is None:
            effective_prompt = get_vietnamese_initial_prompt(include_english=True)
        
        # Transcribe vá»›i cÃ¡c tham sá»‘ tá»‘i Æ°u - CHUáº¨N cho tiáº¿ng Viá»‡t
        try:
            transcribe_kwargs = {
                "language": language,  # QUAN TRá»ŒNG: Pháº£i chá»‰ Ä‘á»‹nh language
                "task": task,
                "verbose": False,  # QUAN TRá»ŒNG: verbose=False Ä‘á»ƒ trÃ¡nh output lá»—i
                "fp16": False,  # QUAN TRá»ŒNG: fp16=False Ä‘á»ƒ trÃ¡nh lá»—i vÃ  Ä‘áº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c
                "beam_size": beam_size,
                "temperature": temperature,
                "condition_on_previous_text": condition_on_previous_text,
                "best_of": best_of,
            }
            
            # Chá»‰ thÃªm initial_prompt náº¿u cÃ³
            if effective_prompt:
                transcribe_kwargs["initial_prompt"] = effective_prompt
            
            result = model.transcribe(
                audio_path_to_use,
                **transcribe_kwargs
            )
            return result
        except FileNotFoundError as fnf_err:
            error_msg = str(fnf_err)
            st.error(f"âŒ FileNotFoundError: {error_msg}")
            st.error(f"âŒ File path: {audio_path_to_use}")
            st.warning("""
            **WinError 2 - File khÃ´ng tÃ¬m tháº¥y:**
            1. File cÃ³ thá»ƒ Ä‘Ã£ bá»‹ xÃ³a
            2. Path khÃ´ng Ä‘Ãºng
            3. FFmpeg khÃ´ng tÃ¬m tháº¥y (náº¿u lá»—i xáº£y ra trong quÃ¡ trÃ¬nh load audio)
            
            **Kháº¯c phá»¥c:**
            - Kiá»ƒm tra file cÃ³ tá»“n táº¡i khÃ´ng
            - Kiá»ƒm tra FFmpeg setup
            - Thá»­ láº¡i vá»›i file audio khÃ¡c
            """)
            return None
        except OSError as os_err:
            # WinError 2 on Windows
            if getattr(os_err, 'winerror', None) == 2 or os_err.errno == 2:
                error_msg = str(os_err)
                st.error(f"âŒ WinError 2: {error_msg}")
                st.error(f"âŒ File path: {audio_path_to_use}")
                st.warning("""
                **WinError 2 - File khÃ´ng tÃ¬m tháº¥y (Windows):**
                - File cÃ³ thá»ƒ Ä‘Ã£ bá»‹ xÃ³a hoáº·c khÃ´ng tá»“n táº¡i
                - FFmpeg khÃ´ng tÃ¬m tháº¥y
                - Path cÃ³ váº¥n Ä‘á»
                
                **ÄÃ£ kiá»ƒm tra:**
                - File existence: âœ…
                - File readable: âœ…
                - CÃ³ thá»ƒ lÃ  lá»—i FFmpeg hoáº·c Whisper internal
                """)
            return None
    except KeyError as ke:
        # Handle "missing field" errors during transcription
        error_msg = f"Missing field error during transcription: {str(ke)}"
        st.error(f"âŒ Lá»—i 'missing field' khi transcribe. ÄÃ¢y thÆ°á»ng do model cache bá»‹ lá»—i.")
        st.warning("""
        **Kháº¯c phá»¥c:**
        1. XÃ³a cache Whisper: `rm -rf ~/.cache/whisper`
        2. Restart á»©ng dá»¥ng vÃ  thá»­ láº¡i
        3. Náº¿u váº«n lá»—i, thá»­ model size nhá» hÆ¡n
        """)
        return None
    except OSError as os_err:
        # Handle WinError 2 specifically
        error_msg = str(os_err)
        if getattr(os_err, 'winerror', None) == 2 or os_err.errno == 2:
            st.error(f"âŒ WinError 2: File khÃ´ng tÃ¬m tháº¥y")
            st.error(f"âŒ Chi tiáº¿t: {error_msg}")
            st.warning("""
            **WinError 2 trÃªn Windows:**
            - File khÃ´ng tá»“n táº¡i hoáº·c Ä‘Ã£ bá»‹ xÃ³a
            - FFmpeg khÃ´ng tÃ¬m tháº¥y
            - Path cÃ³ váº¥n Ä‘á»
            
            **ÄÃ£ thá»­:**
            - Kiá»ƒm tra file existence
            - Táº¡o safe temp copy
            - Retry mechanism
            """)
        else:
            st.error(f"âŒ Lá»—i OS: {error_msg}")
        return None
    except Exception as e:
        error_msg = str(e)
        # Check for FFmpeg errors
        if "ffmpeg" in error_msg.lower() or "ffmpeg was not found" in error_msg.lower():
            st.error(f"âŒ Lá»—i FFmpeg khi transcribe: {error_msg}")
            st.warning("ğŸ’¡ Äáº£m báº£o FFmpeg Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t vÃ  cáº¥u hÃ¬nh Ä‘Ãºng.")
        elif "failed to load audio" in error_msg.lower() or "cannot load audio" in error_msg.lower():
            st.error(f"âŒ Lá»—i khi load audio: {error_msg}")
            st.warning("""
            ğŸ’¡ **NguyÃªn nhÃ¢n cÃ³ thá»ƒ:**
            - File format khÃ´ng Ä‘Æ°á»£c há»— trá»£ hoáº·c bá»‹ há»ng
            - FFmpeg khÃ´ng tÃ¬m tháº¥y hoáº·c khÃ´ng hoáº¡t Ä‘á»™ng
            - File path cÃ³ váº¥n Ä‘á» (khoáº£ng tráº¯ng, kÃ½ tá»± Ä‘áº·c biá»‡t)
            - File Ä‘ang bá»‹ khÃ³a bá»Ÿi process khÃ¡c
            
            **Kháº¯c phá»¥c:**
            - Thá»­ upload láº¡i file audio
            - Kiá»ƒm tra format file (WAV, MP3, FLAC, M4A, OGG)
            - Kiá»ƒm tra FFmpeg setup
            """)
        elif "cannot find the file" in error_msg.lower() or "No such file" in error_msg:
            st.error(f"âŒ File khÃ´ng tÃ¬m tháº¥y: {error_msg}")
            st.warning("ğŸ’¡ File cÃ³ thá»ƒ Ä‘Ã£ bá»‹ xÃ³a hoáº·c path khÃ´ng Ä‘Ãºng.")
        else:
            st.error(f"Lá»—i khi transcribe: {error_msg}")
        return None

def format_transcript(result: Dict, with_timestamps: bool = True, readable: bool = True) -> str:
    """
    Format transcript tá»« káº¿t quáº£ Whisper vá»›i segments dá»… Ä‘á»c
    
    Args:
        result: Whisper result dict
        with_timestamps: CÃ³ hiá»ƒn thá»‹ timestamps khÃ´ng
        readable: CÃ³ chia thÃ nh segments dá»… Ä‘á»c khÃ´ng (7-15 tá»«, â‰¤6s)
    
    Returns:
        Formatted transcript string
    """
    if result is None:
        return ""
    
    text = result.get("text", "")
    segments = result.get("segments", [])
    
    if not with_timestamps or not segments:
        return text
    
    # Chia láº¡i segments cho dá»… Ä‘á»c náº¿u cáº§n
    if readable:
        segments = split_segments_readable(segments, max_words=15, max_duration=6.0)
    
    # Format vá»›i timestamps
    formatted_lines = []
    for segment in segments:
        start = segment.get("start", 0)
        end = segment.get("end", 0)
        segment_text = segment.get("text", "").strip()
        
        if segment_text:
            formatted_lines.append(f"[{format_time(start)} - {format_time(end)}] {segment_text}")
    
    return "\n".join(formatted_lines)

def format_time(seconds: float) -> str:
    """
    Format thá»i gian tá»« seconds sang format dá»… Ä‘á»c [0.00 - 3.20]
    Chuáº©n cho subtitle/transcript dá»… Ä‘á»c
    """
    return f"{seconds:.2f}"


def split_text_readable(text: str, max_words: int = 15, max_sentences: int = 2) -> List[str]:
    """
    Chia text thÃ nh cÃ¡c Ä‘oáº¡n dá»… Ä‘á»c
    
    TiÃªu chuáº©n:
    - 7-15 tá»« má»—i Ä‘oáº¡n (max_words)
    - KhÃ´ng quÃ¡ 2 cÃ¢u má»—i Ä‘oáº¡n (max_sentences)
    - Má»—i Ä‘oáº¡n â‰¤ 5-6 giÃ¢y khi Ä‘á»c
    
    Args:
        text: Text cáº§n chia
        max_words: Sá»‘ tá»« tá»‘i Ä‘a má»—i Ä‘oáº¡n (default: 15)
        max_sentences: Sá»‘ cÃ¢u tá»‘i Ä‘a má»—i Ä‘oáº¡n (default: 2)
    
    Returns:
        List cÃ¡c Ä‘oáº¡n text Ä‘Ã£ chia
    """
    if not text or not text.strip():
        return []
    
    import re
    
    # Chia theo cÃ¢u (giá»¯ láº¡i dáº¥u cÃ¢u)
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    
    chunks = []
    current_chunk = []
    current_word_count = 0
    
    for sentence in sentences:
        if not sentence.strip():
            continue
            
        words = sentence.split()
        word_count = len(words)
        
        # Náº¿u cÃ¢u hiá»‡n táº¡i quÃ¡ dÃ i, chia nhá» cÃ¢u Ä‘Ã³
        if word_count > max_words:
            # Chia cÃ¢u thÃ nh cÃ¡c pháº§n nhá» hÆ¡n
            for i in range(0, word_count, max_words):
                part = " ".join(words[i:i + max_words])
                chunks.append(part.strip())
        else:
            # Kiá»ƒm tra xem cÃ³ thá»ƒ thÃªm cÃ¢u nÃ y vÃ o chunk hiá»‡n táº¡i khÃ´ng
            if (len(current_chunk) < max_sentences and 
                current_word_count + word_count <= max_words):
                # CÃ³ thá»ƒ thÃªm vÃ o chunk hiá»‡n táº¡i
                current_chunk.append(sentence)
                current_word_count += word_count
            else:
                # LÆ°u chunk hiá»‡n táº¡i vÃ  báº¯t Ä‘áº§u chunk má»›i
                if current_chunk:
                    chunks.append(" ".join(current_chunk).strip())
                current_chunk = [sentence]
                current_word_count = word_count
    
    # ThÃªm chunk cuá»‘i cÃ¹ng náº¿u cÃ²n
    if current_chunk:
        chunks.append(" ".join(current_chunk).strip())
    
    return [chunk for chunk in chunks if chunk]


def split_segments_readable(segments: List[Dict], max_words: int = 15, max_duration: float = 6.0) -> List[Dict]:
    """
    Chia láº¡i Whisper segments thÃ nh cÃ¡c Ä‘oáº¡n dá»… Ä‘á»c hÆ¡n
    
    Args:
        segments: List segments tá»« Whisper (cÃ³ start, end, text)
        max_words: Sá»‘ tá»« tá»‘i Ä‘a má»—i Ä‘oáº¡n (default: 15)
        max_duration: Thá»i gian tá»‘i Ä‘a má»—i Ä‘oáº¡n (giÃ¢y, default: 6.0)
    
    Returns:
        List segments má»›i vá»›i text Ä‘Ã£ Ä‘Æ°á»£c chia nhá» vÃ  timestamps má»›i
    """
    readable_segments = []
    
    for seg in segments:
        start = seg.get("start", 0)
        end = seg.get("end", 0)
        text = seg.get("text", "").strip()
        
        if not text:
            continue
        
        # Chia text thÃ nh cÃ¡c Ä‘oáº¡n nhá»
        sub_texts = split_text_readable(text, max_words=max_words, max_sentences=2)
        
        if not sub_texts:
            continue
        
        # TÃ­nh thá»i gian cho má»—i Ä‘oáº¡n
        duration = end - start
        num_parts = len(sub_texts)
        per_part = duration / num_parts if num_parts > 0 else duration
        
        # Táº¡o segments má»›i vá»›i timestamps Ä‘Æ°á»£c chia Ä‘á»u
        for i, sub_text in enumerate(sub_texts):
            seg_start = round(start + i * per_part, 2)
            seg_end = round(start + (i + 1) * per_part, 2)
            
            # Äáº£m báº£o khÃ´ng vÆ°á»£t quÃ¡ max_duration
            if seg_end - seg_start > max_duration:
                # Náº¿u má»™t Ä‘oáº¡n quÃ¡ dÃ i, chia Ä‘á»u láº¡i
                words = sub_text.split()
                if len(words) > max_words:
                    words_per_part = max_words
                    num_sub_parts = (len(words) + words_per_part - 1) // words_per_part
                    sub_duration = (seg_end - seg_start) / num_sub_parts
                    
                    for j in range(0, len(words), words_per_part):
                        part_text = " ".join(words[j:j + words_per_part])
                        part_start = seg_start + (j // words_per_part) * sub_duration
                        part_end = min(seg_start + ((j // words_per_part) + 1) * sub_duration, seg_end)
                        
                        readable_segments.append({
                            "start": round(part_start, 2),
                            "end": round(part_end, 2),
                            "text": part_text.strip()
                        })
                else:
                    readable_segments.append({
                        "start": seg_start,
                        "end": seg_end,
                        "text": sub_text.strip()
                    })
    else:
                readable_segments.append({
                    "start": seg_start,
                    "end": seg_end,
                    "text": sub_text.strip()
                })
    
    return readable_segments

def get_transcript_statistics(result: Dict, duration: float) -> Dict:
    """TÃ­nh toÃ¡n thá»‘ng kÃª transcript"""
    if result is None:
        return {}
    
    text = result.get("text", "")
    words = text.split()
    
    return {
        'word_count': len(words),
        'character_count': len(text),
        'duration': duration,
        'words_per_minute': (len(words) / duration * 60) if duration > 0 else 0,
        'segments_count': len(result.get("segments", []))
    }

